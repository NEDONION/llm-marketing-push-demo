import OpenAI from 'openai';
import {
  Channel,
  Locale,
  Candidate,
  PromptBuildRequest,
  PromptBuildResponse,
  LLMGenerateRequest,
  LLMGenerateResponse,
  UserSignals
} from '../../types/index.js';
import { catalogService } from '../catalog/catalog.service.js';
import {getSystemPromptByChannel} from "../../prompts/index.js";

/**
 * LLM æœåŠ¡ - è´Ÿè´£ Prompt æ„å»ºå’Œç”Ÿæˆ
 */
export class LLMService {
  private openai: OpenAI;

  constructor() {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
      baseURL: process.env.OPENAI_BASE_URL,
    });
  }

  /**
   * æ„å»º Prompt
   */
  async buildPrompt(request: PromptBuildRequest): Promise<PromptBuildResponse> {
    const { userId, channel, locale, maxLen, items, userSignals, constraints } = request;

    // è·å–å•†å“ä¿¡æ¯
    const itemDetails = await catalogService.getItems(items.map(i => i.itemId));

    // æ„å»ºå•†å“æè¿°ï¼ˆåŒ…å«å•†å“ IDï¼‰
    const itemDescriptions = Array.from(itemDetails.values()).map(item =>
        `å•†å“ID: ${item.itemId}\nã€${item.brand || ''}ã€‘${item.title} - $${item.price}`
    ).join('\n\n');

    // è·å–å½“å‰èŠ‚æ—¥
    const currentHolidays = catalogService.getCurrentHolidays(locale);
    const holidayContext = currentHolidays.length > 0
        ? `å½“å‰ä¿ƒé”€æ´»åŠ¨ï¼š${currentHolidays.map(h => h.name).join('ã€')}`
        : '';

    // æ„å»ºç”¨æˆ·è¡Œä¸ºä¸Šä¸‹æ–‡
    const userContext = this.buildUserContext(userSignals);

    // æ ¹æ®æ¸ é“é€‰æ‹©ç³»ç»Ÿæç¤ºè¯ï¼ˆä½ ç°åœ¨ç”¨çš„æ˜¯ this.getSystemPromptï¼›ä¹‹åä¹Ÿå¯ä»¥æ›¿æ¢æˆå¤–éƒ¨ promptsï¼‰
    const systemPrompt = this.getSystemPrompt(channel, locale, maxLen, constraints);

    // ğŸ”¹ æ ¹æ®æ¸ é“å®šä¹‰ä¸åŒçš„ JSON è¿”å›æ ¼å¼
    const outputSchema =
        channel === 'PUSH'
            ? `
Please return the information referenced in your copy in JSON format:
{
  "text": "Generated push copy",
  "claims": {
    "referenced_item_ids": ["Item ID list (must use complete Item IDs provided above, format: v1|itm|001)"],
    "referenced_brands": ["Brand list"],
    "referenced_events": ["Referenced user behaviors, e.g., recent_view, recent_add_to_cart"],
    "referenced_holiday": "Holiday name or null",
    "mentioned_benefits": ["Mentioned benefits, e.g., free shipping, discounts"]
  }
}
`
            : `
Please return the EMAIL content in JSON format:
{
  "subject": "Email subject line",
  "preview": "Short preview text shown in inbox list",
  "body": "Main email body text (plain text, no HTML)",
  "bullets": ["Optional bullet 1", "Optional bullet 2"],
  "cta": "Call-to-action text, e.g. 'Shop Now'",
  "claims": {
    "referenced_item_ids": ["Item ID list (must use complete Item IDs provided above, format: v1|itm|001)"],
    "referenced_brands": ["Brand list"],
    "referenced_events": ["Referenced user behaviors, e.g., recent_view, recent_add_to_cart"],
    "referenced_holiday": "Holiday name or null",
    "mentioned_benefits": ["Mentioned benefits, e.g., free shipping, discounts"]
  }
}
`;

    // æ„å»ºå®Œæ•´çš„ prompt
    const prompt = `${systemPrompt}

ã€User Profileã€‘
${userContext}

ã€Recommended Itemsã€‘
${itemDescriptions}

${holidayContext}

Please generate ${channel === 'PUSH' ? 'a short push notification' : 'a personalized marketing email'} with the following requirements:
1. Length not exceeding ${maxLen} characters${channel === 'EMAIL' ? ' for the email body' : ''}
2. ${constraints.noUrl ? 'No URLs allowed' : 'URLs are allowed if needed'}
3. ${constraints.noPrice ? 'Do not display prices directly' : 'You may mention prices if helpful'}
4. Based on user's recent behavior (${userSignals.recent_view} views, ${userSignals.recent_add_to_cart} add-to-cart)
5. Friendly and personalized tone that sparks user interest

${outputSchema}

IMPORTANT: referenced_item_ids must use the complete Item IDs provided in ã€Recommended Itemsã€‘ (format: v1|itm|xxx), DO NOT use product names!
IMPORTANT: You MUST return ONLY a valid JSON object, no explanations or markdown.`;

    return {
      prompt,
      generationHints: {
        nCandidates: channel === 'PUSH' ? 3 : 2,
        temperature: 0.7
      }
    };
  }


  /**
   * è°ƒç”¨ LLM ç”Ÿæˆå€™é€‰æ–‡æ¡ˆï¼ˆå…¼å®¹ PUSH / EMAIL ä¸¤ç§è¾“å‡º schemaï¼‰
   */
  async generate(request: LLMGenerateRequest): Promise<LLMGenerateResponse> {
    const { prompt, n } = request;

    try {
      const completion = await this.openai.chat.completions.create({
        model: 'openai/gpt-4o-mini',
        messages: [{ role: 'user', content: prompt }],
        n,
        temperature: 0.7,
        response_format: { type: 'json_object' }
      });

      const candidates: Candidate[] = [];

      for (const choice of completion.choices) {
        try {
          const content = choice.message.content;
          if (!content) continue;

          const parsed = JSON.parse(content);

          // ğŸ”¥ å…¼å®¹ä¸¤ç§ç»“æ„ï¼šPUSH ä¸ EMAIL
          candidates.push({
            // email ä¼šä¼˜å…ˆä½¿ç”¨ subject/bodyï¼Œå¦åˆ™ fallback åˆ° text
            text: parsed.text ?? parsed.body ?? '',

            claims: parsed.claims || {
              referenced_item_ids: [],
              referenced_brands: [],
              referenced_events: [],
              referenced_holiday: null,
              mentioned_benefits: []
            },

            model: completion.model,
            token: completion.usage?.total_tokens,

            // ğŸ“Œ Email ç‹¬æœ‰å­—æ®µ
            subject: parsed.subject,
            preview: parsed.preview,
            body: parsed.body,
            bullets: parsed.bullets,
            cta: parsed.cta
          });

        } catch (e) {
          console.error('Failed to parse LLM response:', e);
          candidates.push({
            text: choice.message.content ?? '',
            claims: {
              referenced_item_ids: [],
              referenced_brands: [],
              referenced_events: [],
              referenced_holiday: null,
              mentioned_benefits: []
            },
            model: completion.model
          });
        }
      }

      return { candidates };

    } catch (error) {
      console.error('LLM generation error:', error);
      throw new Error(`LLM generation failed: ${error}`);
    }
  }


  /**
   * æ„å»ºç”¨æˆ·è¡Œä¸ºä¸Šä¸‹æ–‡
   */
  private buildUserContext(signals: UserSignals): string {
    const parts: string[] = [];

    if (signals.recent_view > 0) {
      parts.push(`Viewed ${signals.recent_view} items in the last 7 days`);
    }

    if (signals.recent_add_to_cart > 0) {
      parts.push(`Added ${signals.recent_add_to_cart} items to cart`);
    }

    if (signals.recent_purchase > 0) {
      parts.push(`Purchased ${signals.recent_purchase} items`);
    }

    if (signals.tags.length > 0) {
      parts.push(`Interested in: ${signals.tags.slice(0, 3).join(', ')}`);
    }

    if (signals.favorite_brands && signals.favorite_brands.length > 0) {
      parts.push(`Favorite brands: ${signals.favorite_brands.slice(0, 3).join(', ')}`);
    }

    return parts.join('; ') || 'New user';
  }

  /**
   * è·å–ç³»ç»Ÿæç¤ºè¯
   */
  private getSystemPrompt(
    channel: Channel,
    locale: Locale,
    maxLen: number,
    constraints: any
  ): string {
    return getSystemPromptByChannel(channel, locale, maxLen, constraints);
  }
}

// å»¶è¿Ÿå®ä¾‹åŒ–ï¼Œç¡®ä¿ç¯å¢ƒå˜é‡å·²åŠ è½½
let _llmServiceInstance: LLMService | null = null;

export const llmService = {
  get instance(): LLMService {
    if (!_llmServiceInstance) {
      _llmServiceInstance = new LLMService();
    }
    return _llmServiceInstance;
  }
};
